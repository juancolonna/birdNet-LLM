# ---- IMPORTS for BirdNET ----
from birdnetlib import Recording
from birdnetlib.analyzer import Analyzer

# ---- IMPORTS for Streamlit ----
import streamlit as st
from datetime import datetime
import tempfile
import os
import yaml
import re
import asyncio

# ---- GENERAL IMPORTS for the agent ----
import matplotlib.pyplot as plt
import numpy as np
import math
import seaborn as sns
import pandas as pd

# ------- Tool function for the agent --------
from agents import Agent, Runner, function_tool, ModelSettings

os.makedirs("graficos", exist_ok=True)  # Create if it doesn't exist

def limpa_markdown_img(texto):
    """
    Remove any Markdown image line.
    """
    return re.sub(r"!\[.*?\]\([^)]+\)\n?", "", texto)

@function_tool
def executar_codigo(codigo: str) -> object:
    """
    Executes the code generated by the agent with access to df, plt, np, pd, and math.
    Handles DataFrame, Series, Figure, and returns the appropriate result for Streamlit display.
    """
    df = st.session_state.df
    if df.empty:
        return "⚠️ No DataFrame has been generated yet. Please run a detection first."
    else:
        print("\n========== CODE GENERATED BY THE AGENT ==========")
        print(codigo)
        print("==============================================\n")
        local_vars = {"df": df, "plt": plt, "np": np, "pd": pd, "math": math}
        exec(codigo, globals(), local_vars)
        resultado = local_vars.get("resultado", None)
        # If not a Figure, but there is an open plot, return plt.gcf()
        if not isinstance(resultado, plt.Figure) and plt.get_fignums():
            resultado = plt.gcf()
        # Handle Series (e.g. resultado = df['column'].value_counts())
        if isinstance(resultado, pd.Series):
            resultado = resultado.to_frame()
        return resultado
    
# ------- Instantiate agent only once -------
if "df_agent" not in st.session_state:
    df_agent = Agent(
        name="Agente BirdNET",
        tools=[executar_codigo],
        model_settings=ModelSettings(tool_choice="required"),
        instructions=(
            "You are an agent that answers questions about a DataFrame called 'df'. "
            "It contains bird vocalization detection results using BirdNET. "
            "If the user's question refers to a previous message, politely ask them to restate the complete question. "
            "The columns of df are:\n"
            "- 'common_name': common name of the detected species (e.g. 'Spotted Towhee')\n"
            "- 'scientific_name': scientific name of the detected species (e.g. 'Pipilo maculatus')\n"
            "- 'start_time': start time of the detected vocalization in the audio file (in seconds)\n"
            "- 'end_time': end time of the detected vocalization (in seconds)\n"
            "- 'confidence': detection confidence, between 0 and 1\n"
            "- 'label': internal label of the species (used by the model)\n"
            "- 'file': analyzed audio file name\n"
            "- 'date': recording date (format YYYY-MM-DD)\n"
            "- 'lat': recording latitude\n"
            "- 'lon': recording longitude\n"
            "- 'min_conf': minimum confidence used in the analysis\n"
            "- 'week_48': week number used in analysis (according to BirdNET)\n\n"
            "If you don't understand the question, reply with 'Sorry, I didn't understand the question.' "
            "When any kind of plot is requested, avoid returning the plot as markdown. "
            "If the question refers to columns not in the dataframe, return the question asking for clarification. "
            "Generate Python code using pandas, numpy, math, or matplotlib as needed. "
            "Always assign your result to the variable 'resultado':\n"
            "- For plots, use: resultado = plt.gcf()\n"
            "- For tables or series, use: resultado = <dataframe or series>\n"
            "- For text answers, use: resultado = 'explanatory text'.\n"
            "Do not use plt.show()."
            "Never make assumptions about the content of 'df'. "
            "Never create, read, or overwrite the DataFrame 'df' — just use the existing DataFrame 'df'. "
            "Never use 'import pandas', nor create sample or fake DataFrames. "
            "Always work with the real data already loaded in df."
        ),
    )
    df_agent.model_settings.temperature = 0.1
    st.session_state.df_agent = df_agent

# ---- Helper function to build a flexible datetime ----
def build_datetime_from_audio(audio, fallback=None):
    """
    Build a datetime from fields available in the audio (dict).
    Missing hour/min/sec fields default to zero.
    Returns None if at least year, month, and day are missing.
    """
    year = audio.get("year")
    month = audio.get("month")
    day = audio.get("day")
    if year and month and day:
        hour = audio.get("hour", 0)
        minute = audio.get("min", 0)
        second = audio.get("sec", 0)
        try:
            return datetime(int(year), int(month), int(day), int(hour), int(minute), int(second))
        except Exception:
            return fallback
    return fallback

# ---- Streamlit global config ----
st.set_page_config(layout="wide")

# ================== SIDEBAR PANEL ==================
st.sidebar.title("Configuration")
openai_token = st.sidebar.text_input("OpenAI API Token", type="password")
if openai_token:
    st.session_state["openai_token"] = openai_token
    st.sidebar.success("Token saved in session.")
    os.environ["OPENAI_API_KEY"] = openai_token

min_conf = st.sidebar.slider(
    "Minimum confidence value", 0.01, 0.99, 0.5, step=0.01, key="min_conf_slider"
)

config_file = st.sidebar.file_uploader(
    "Configuration file (config.yaml)",
    type=["yaml", "yml"],
    accept_multiple_files=False
)

audio_files = st.sidebar.file_uploader(
    "Upload your audio files (one or more)",
    type=["wav", "mp3", "flac"],
    accept_multiple_files=True
)

executar = st.sidebar.button("Run analysis")

# =============== PARAMETERS AND STATE CONTROL ===============
if "df" not in st.session_state:
    st.session_state.df = pd.DataFrame({
        'common_name': pd.Series(dtype='str'),
        'scientific_name': pd.Series(dtype='str'),
        'start_time': pd.Series(dtype='float'),
        'end_time': pd.Series(dtype='float'),
        'confidence': pd.Series(dtype='float'),
        'label': pd.Series(dtype='str'),
        'file': pd.Series(dtype='str'),
        'date': pd.Series(dtype='datetime64[ns]'),
        'lat': pd.Series(dtype='float'),
        'lon': pd.Series(dtype='float'),
        'min_conf': pd.Series(dtype='float'),
        'week_48': pd.Series(dtype='Int64'),
    })
if "messages" not in st.session_state:
    st.session_state.messages = []
if "processed_files" not in st.session_state:
    st.session_state.processed_files = set()

# =============== INTELLIGENT PROCESSING ===============
if executar and (audio_files or config_file):
    with st.spinner("Processing detections..."):
        if config_file is not None:
            config = yaml.safe_load(config_file)
            audios = config.get("audios", [])
        else:
            audios = []
        yaml_audio_dict = {audio["file"]: audio for audio in audios}
        st.session_state.df = pd.DataFrame({
            'common_name': pd.Series(dtype='str'),
            'scientific_name': pd.Series(dtype='str'),
            'start_time': pd.Series(dtype='float'),
            'end_time': pd.Series(dtype='float'),
            'confidence': pd.Series(dtype='float'),
            'label': pd.Series(dtype='str'),
            'file': pd.Series(dtype='str'),
            'date': pd.Series(dtype='datetime64[ns]'),
            'lat': pd.Series(dtype='float'),
            'lon': pd.Series(dtype='float'),
            'min_conf': pd.Series(dtype='float'),
            'week_48': pd.Series(dtype='Int64'),
        })
        st.session_state.messages = []
        st.session_state.processed_files = set()

        analyzer = Analyzer()
        Detections = []

        audio_files_dict = {f.name: f for f in audio_files} if audio_files else {}

        for file_name, uploaded_audio in audio_files_dict.items():
            audio_params = yaml_audio_dict.get(file_name, {})
            suffix = "." + file_name.split(".")[-1]
            with tempfile.NamedTemporaryFile(delete=False, suffix=suffix) as tmp_file:
                tmp_file.write(uploaded_audio.read())
                temp_path = tmp_file.name

            st.session_state.messages.append({"role": "user", "content": f"File {file_name}"})

            recording_args = dict(
                analyzer=analyzer,
                path=temp_path,
                min_conf=min_conf,
            )

            if audio_params:
                if "lat" in audio_params:
                    recording_args["lat"] = audio_params["lat"]
                if "lon" in audio_params:
                    recording_args["lon"] = audio_params["lon"]
                if "week_48" in audio_params:
                    recording_args["week_48"] = audio_params["week_48"]

                dt = build_datetime_from_audio(audio_params)
                if not dt:
                    m = re.search(r"(\d{4})-(\d{2})-(\d{2})-birdnet-(\d{2}):(\d{2}):(\d{2})", file_name)
                    if m:
                        try:
                            dt = datetime(
                                int(m.group(1)), int(m.group(2)), int(m.group(3)),
                                int(m.group(4)), int(m.group(5)), int(m.group(6))
                            )
                        except Exception as e:
                            st.session_state.messages.append({"role": "assistant", "content": f"Error inferring date from {file_name}: {str(e)}", "error": True})
                if dt:
                    recording_args["date"] = dt
            else:
                m = re.search(r"(\d{4})-(\d{2})-(\d{2})-birdnet-(\d{2}):(\d{2}):(\d{2})", file_name)
                if m:
                    try:
                        dt = datetime(
                            int(m.group(1)), int(m.group(2)), int(m.group(3)),
                            int(m.group(4)), int(m.group(5)), int(m.group(6))
                        )
                        recording_args["date"] = dt
                    except Exception as e:
                        st.session_state.messages.append({"role": "assistant", "content": f"Error inferring date from {file_name}: {str(e)}", "error": True})

            recording = Recording(**recording_args)
            try:
                recording.analyze()
            except Exception as e:
                st.session_state.messages.append({"role": "assistant", "content": f"Error analyzing {file_name}: {str(e)}", "error": True})
                os.remove(temp_path)
                continue

            if recording.detections:
                response = f"Detected species:\n"
                for det in recording.detections:
                    if det['common_name'] not in response:
                        response += f"- **{det['common_name']}** ({det['scientific_name']})\n"
                    det["file"] = file_name
                    det["date"] = getattr(recording, "date", pd.NaT)
                    det["lat"] = audio_params.get("lat") if audio_params else None
                    det["lon"] = audio_params.get("lon") if audio_params else None
                    det["min_conf"] = min_conf
                    det["week_48"] = audio_params.get("week_48", pd.NA) if audio_params else pd.NA
                    det["label"] = det.get("label", "")
                    Detections.append(det)
            else:
                response = f"No species detected in **{file_name}**."

            st.session_state.messages.append({"role": "assistant", "content": response})
            st.session_state.processed_files.add(file_name)
            os.remove(temp_path)

        for yaml_name in yaml_audio_dict:
            if yaml_name not in audio_files_dict:
                st.session_state.messages.append(
                    {
                        "role": "assistant",
                        "content": f"File **{yaml_name}** is listed in the YAML but was not uploaded for analysis.",
                        "error": True
                    }
                )

        if Detections:
            new_df = pd.DataFrame(Detections)
            if st.session_state.df.empty:
                st.session_state.df = new_df
            else:
                st.session_state.df = pd.concat([st.session_state.df, new_df], ignore_index=True)

# ================== MAIN INTERFACE WITH TABS ==================
st.title("BirdNET Audio Chat")

tab1, tab2, tab3 = st.tabs(["💬 Chat", "📊 Detections", "🗺️ Map"])

# ---------------- TAB CHAT ----------------
with tab1:
    # 1. PROCESS THE PENDING PROMPT
    if "pending_user_prompt" in st.session_state:
        prompt = st.session_state.pending_user_prompt
        del st.session_state.pending_user_prompt

        st.session_state.messages.append({"role": "user", "content": prompt})
        input_formatado = prompt.strip()
        resposta = asyncio.run(Runner.run(st.session_state.df_agent, input=input_formatado))

        print('response: ', resposta)

        fig = None
        df_result = None
        text_result = limpa_markdown_img(resposta.final_output)
        for item in getattr(resposta, "new_items", []):
            if hasattr(item, "output"):
                if isinstance(item.output, plt.Figure):
                    fig = item.output
                elif isinstance(item.output, pd.DataFrame):
                    df_result = item.output

        msg = {
            "role": "assistant",
            "content": text_result
        }
        if fig:
            msg["figure"] = fig
        if df_result is not None:
            msg["dataframe"] = df_result

        st.session_state.messages.append(msg)

    # 2. DISPLAY THE CHAT HISTORY USING st.chat_message
    for msg in st.session_state.messages:
        with st.chat_message(msg["role"], avatar="🦜" if msg["role"] == "assistant" else "👤"):
            st.markdown(msg["content"])
            if msg.get("figure"):
                st.pyplot(msg["figure"])
            if msg.get("dataframe") is not None:
                df_out = msg["dataframe"]
                if df_out.shape[0] > 100:
                    st.dataframe(df_out.head(100), use_container_width=True)
                    st.caption(f"Showing the first 100 of {df_out.shape[0]} rows.")
                else:
                    st.dataframe(df_out, use_container_width=True)

    # 3. USER INPUT FIELD
    user_prompt = st.chat_input(
        "Ask something about the detections or request a plot",
        key="main_chat_input",
        disabled=not bool(st.session_state.get("openai_token"))
    )
    if not st.session_state.get("openai_token"):
        st.warning("Please enter the API token in the sidebar to chat with the AI.")
    if user_prompt:
        st.session_state.pending_user_prompt = user_prompt
        st.rerun()

# ---------------- TAB DETECTIONS ----------------
with tab2:
    st.markdown("### Aggregated Detections")
    if not st.session_state.df.empty:
        st.dataframe(st.session_state.df, use_container_width=True)
        csv = st.session_state.df.to_csv(index=False).encode('utf-8')
        st.download_button(
            label="Download CSV",
            data=csv,
            file_name='birdnet_detections.csv',
            mime='text/csv'
        )
    else:
        st.info("No detections yet.")

# ---------------- TAB MAP ----------------
with tab3:
    st.markdown("### Detection Map")
    df_map = st.session_state.df[["lat", "lon"]].dropna().drop_duplicates()
    if not df_map.empty:
        st.map(df_map)
    else:
        st.info("No points to display on the map.")
